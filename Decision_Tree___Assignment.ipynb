{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Code: DA-AG-012\n",
        "#Decision Tree | Assignment"
      ],
      "metadata": {
        "id": "kCM5pu-9IsWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of classification?\n",
        "\n",
        "Answer:\n",
        "\n",
        "A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. In the context of classification, it works by learning rules from the features to split the dataset into smaller groups.\n",
        "\n",
        "Each internal node in the tree represents a test on a feature.\n",
        "\n",
        "Each branch represents the outcome of the test.\n",
        "\n",
        "Each leaf node represents a class label.\n",
        "\n",
        "The model splits the dataset recursively based on the most informative features until the stopping criteria are met (like pure nodes or max depth). The goal is to reduce impurity in each split.\n",
        "\n",
        " Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Both Gini Impurity and Entropy are impurity measures used to decide how to split nodes in a Decision Tree.\n",
        "\n",
        "Gini Impurity (formula):\n",
        "\n",
        "Gini = 1 - (p1^2 + p2^2 + ... + pn^2)\n",
        "\n",
        "\n",
        "Entropy (formula):\n",
        "\n",
        "Entropy = - (p1 * log2(p1) + p2 * log2(p2) + ... + pn * log2(pn))\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "p1, p2, ..., pn are the probabilities of each class in the node.\n",
        "\n",
        "Impact on Splits:\n",
        "\n",
        "The Decision Tree calculates the decrease in impurity after each possible split.\n",
        "\n",
        "It selects the split that reduces impurity the most.\n",
        "\n",
        "This results in purer child nodes and better classification.\n",
        "\n",
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Pre-Pruning (Early Stopping):\n",
        "\n",
        "Limits the growth of the tree during training using parameters like max_depth, min_samples_split, etc.\n",
        "\n",
        "Advantage: Reduces overfitting and training time.\n",
        "\n",
        "Post-Pruning:\n",
        "\n",
        "Allows the tree to grow fully, then removes branches that don’t improve performance using validation data.\n",
        "\n",
        "Advantage: Often leads to better generalization because pruning is based on real model performance.\n",
        "\n",
        " Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Information Gain is the reduction in impurity after a dataset is split on a feature.\n",
        "\n",
        "Formula:\n",
        "\n",
        "Information Gain = Impurity(parent node)\n",
        "                 - [ (n1/n) * Impurity(child1) + (n2/n) * Impurity(child2) + ... ]\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "n1, n2, ... are number of samples in each child node\n",
        "\n",
        "n is the number of samples in the parent node\n",
        "\n",
        "Importance:\n",
        "\n",
        "Helps the tree identify the feature that results in the most significant improvement in class purity.\n",
        "\n",
        "Higher information gain = better feature for splitting.\n",
        "\n",
        " Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Applications:\n",
        "\n",
        "  Disease diagnosis\n",
        "\n",
        "  Loan approval\n",
        "\n",
        "  Fraud detection\n",
        "\n",
        "  Customer churn prediction\n",
        "\n",
        "  Credit scoring\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Easy to understand and visualize\n",
        "\n",
        "Handles both numerical and categorical data\n",
        "\n",
        "Requires little data preprocessing\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Prone to overfitting if not pruned\n",
        "\n",
        "High variance (small changes in data → different tree)\n",
        "\n",
        "Less accurate compared to ensemble methods like Random Forest   \n",
        "\n",
        "\n",
        " Question 6:   Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "● Print the model’s accuracy and feature importances\n",
        "(Include your Python code and output in the code box below.)\n",
        "Answer:  \n",
        "  \n",
        "  \n",
        "   Dataset Info:\n",
        "● Iris Dataset for classification tasks (sklearn.datasets.load_iris() or\n",
        "provided CSV).\n",
        "● Boston Housing Dataset for regression tasks\n",
        "(sklearn.datasets.load_boston() or provided CSV).   \n",
        "Answer:  \n",
        "\n"
      ],
      "metadata": {
        "id": "rpO27Hs0I3_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train classifier\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Feature Importances:\", clf.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFtK8AAeOmrC",
        "outputId": "437280d7-28aa-4e58-f6e3-f3a94cb25e6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Feature Importances: [0.         0.01911002 0.89326355 0.08762643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7:  Write a Python program to:   \n",
        "● Load the Iris Dataset   \n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.   \n",
        "(Include your Python code and output in the code box below.)   \n",
        "Answer:"
      ],
      "metadata": {
        "id": "p_asv6yBOtDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7\n",
        "\n",
        "# Full tree\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "acc_full = accuracy_score(y_test, clf_full.predict(X_test))\n",
        "\n",
        "# Pruned tree\n",
        "clf_pruned = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_pruned.fit(X_train, y_train)\n",
        "acc_pruned = accuracy_score(y_test, clf_pruned.predict(X_test))\n",
        "\n",
        "# Compare\n",
        "print(\"Full Tree Accuracy:\", acc_full)\n",
        "print(\"Pruned Tree Accuracy (max_depth=3):\", acc_pruned)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZlk5XAeO2j5",
        "outputId": "831995dd-807c-4e42-dc76-94f415efab2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Tree Accuracy: 1.0\n",
            "Pruned Tree Accuracy (max_depth=3): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:   \n",
        "● Load the Boston Housing Dataset   \n",
        "● Train a Decision Tree Regressor   \n",
        "● Print the Mean Squared Error (MSE) and feature importances   \n",
        "(Include your Python code and output in the code box below.)   \n",
        "Answer:"
      ],
      "metadata": {
        "id": "9b2IGEFIPAgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8\n",
        "\n",
        "# Use California Housing as replacement for deprecated Boston dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train regressor\n",
        "reg = DecisionTreeRegressor(random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Feature Importances:\", reg.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuqp6HtaPHgM",
        "outputId": "b1d388d8-de29-43aa-9a1c-593704e34d94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.5280096503174904\n",
            "Feature Importances: [0.52345628 0.05213495 0.04941775 0.02497426 0.03220553 0.13901245\n",
            " 0.08999238 0.08880639]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:   \n",
        "● Load the Iris Dataset   \n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV   \n",
        "● Print the best parameters and the resulting model accuracy   \n",
        "(Include your Python code and output in the code box below.)   \n",
        "Answer:  "
      ],
      "metadata": {
        "id": "SIptCWTJPPtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5],\n",
        "    'min_samples_split': [2, 4, 6, 10]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best model and evaluate\n",
        "best_model = grid_search.best_estimator_\n",
        "test_accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Accuracy:\", grid_search.best_score_)\n",
        "print(\"Test Accuracy with Best Parameters:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqsLMW87PUOE",
        "outputId": "8f330a5a-bec1-4903-f1df-1dd1d3a21bc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 6}\n",
            "Best Cross-Validated Accuracy: 0.9428571428571428\n",
            "Test Accuracy with Best Parameters: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.   \n",
        "Explain the step-by-step process you would follow to:  \n",
        "● Handle the missing values   \n",
        "● Encode the categorical features   \n",
        "● Train a Decision Tree model   \n",
        "● Tune its hyperparameters   \n",
        "● Evaluate its performance   \n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.   \n",
        "Answer:   \n",
        "\n",
        "Step-by-step process:\n",
        "\n",
        "1. Handle Missing Values:\n",
        "\n",
        "Use SimpleImputer(strategy='mean') for numeric features.\n",
        "\n",
        "Use SimpleImputer(strategy='most_frequent') for categorical features.\n",
        "\n",
        "2. Encode Categorical Features:\n",
        "\n",
        "Use OneHotEncoder for nominal features.\n",
        "\n",
        "Use ColumnTransformer to combine encoding with numerical columns.\n",
        "\n",
        "3. Train Decision Tree Model:\n",
        "\n",
        "Split data using train_test_split().\n",
        "\n",
        "Train using DecisionTreeClassifier() from sklearn.tree.\n",
        "\n",
        "4. Tune Hyperparameters:\n",
        "\n",
        "Use GridSearchCV to find best max_depth, min_samples_split, etc.\n",
        "\n",
        "5. Evaluate Performance:\n",
        "\n",
        "Use accuracy_score, confusion_matrix, classification_report.\n",
        "\n",
        "In healthcare, focus more on recall to minimize false negatives.\n",
        "\n",
        "Business Value:\n",
        "\n",
        "Early disease detection\n",
        "\n",
        "Better patient care decisions\n",
        "\n",
        "Cost and time savings through automation\n",
        "\n",
        "Explainable predictions (easy for doctors to understand)"
      ],
      "metadata": {
        "id": "spBn7WThQTty"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czIu8pVQPEw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_AyfzCWIq9c"
      },
      "outputs": [],
      "source": []
    }
  ]
}